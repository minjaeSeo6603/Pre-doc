---
title: "Data Task"
author: "Minjae Seo"
date: "March 24, 2025"
output:
  pdf_document:
    toc: no
    number_sections: yes
  html_document:
    toc: no
    df_print: paged
fontsize: 10pt
geometry: margin=0.5in
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

## setting up environment 
rm(list = ls(all.names = TRUE)) # clear all objects including hidden objects
gc() # free up memory and report the memory usage 

# Set working directory

# Install sufficient packages based off the command below
# install.packages(c("tidyverse","knitr","readr")) # uncomment this code to install the packages

# Attach packages
library(tidyverse) # includes ggplot2, for data visualization. dplyr, for data manipulation
library(knitr)       # for kable table formatting
library(xtable)
library(stargazer)
set.seed(123)        # fix the random seed for reproducibility
```

# Experiment Design and Data Simulation

## Baseline Survey Simulation

First, we create a baseline dataset for 5,000 participants.
Each participant gets a unique ID and a set of demographic attributes and baseline vaccine hesitancy responses.
We aim for the demographics to resemble a U.S. adult population distribution.

`ID`: Unique identifier for each participant (1 to 5000).

`Age`: Simulated age in years (18 to 90, with a realistic distribution skewed toward middle age).

`Gender`: Male or Female (approx. 50/50 split).

`Race/Ethnicity`: Categories (White, Black, Hispanic, Asian, Other) with rough proportions based on U.S. population.

`Income`: Annual income category (Low, Medium, High) or approximate income in USD.

`Education`: Education level (e.g., High School or less, Some College, Bachelor's or higher).

`Region`: U.S. region (Northeast, Midwest, South, West) with realistic proportions (South is largest, etc.).

`Hesitancy Questions`: For example, two survey questions assessing vaccine hesitancy:

-   Q1: "Concerned about COVID-19 vaccine side effects" (Likert 1-5, 1 = Not at all, 5 = Very concerned).
-   Q2: "Do not trust the COVID-19 vaccine" (Likert 1-5, 1 = Strongly disagree, 5 = Strongly agree). (Higher values on these indicate greater vaccine hesitancy.)

We will simulate these such that there is variation in hesitancy, with some participants very hesitant and others not at all, to reflect a mix of attitudes.

```{r}
# Number of participants
N <- 5000

# Unique IDs
participant_id <- 1:N

# Age: simulate with a distribution from 18 to 90 (skewing toward middle-aged)
age <- round(rnorm(N, mean = 50, sd = 18))
age[age < 18] <- 18   # enforce minimum age 18
age[age > 90] <- 90   # cap maximum age at 90

# Gender
gender <- sample(c("Male", "Female"), N, replace = TRUE, prob = c(0.49, 0.51))

# Race/Ethnicity: simulate categories with rough US proportions
race <- sample(c("White", "Black", "Hispanic", "Asian", "Other"),
               N, replace = TRUE, prob = c(0.60, 0.13, 0.18, 0.06, 0.03))

# Income: categorize income as Low, Medium, High (roughly 30/40/30 split)
income <- sample(c("Low", "Medium", "High"), N, replace = TRUE, prob = c(0.3, 0.4, 0.3))

# Education: education level distribution (approximate)
education <- sample(c("High School or less", "Some College", "Bachelor's or higher"),
                    N, replace = TRUE, prob = c(0.4, 0.3, 0.3))

# Region: Northeast, Midwest, South, West with realistic proportions
region <- sample(c("Northeast", "Midwest", "South", "West"),
                 N, replace = TRUE, prob = c(0.18, 0.22, 0.37, 0.23))

# Vaccine hesitancy questions at baseline:
# Q1: Concern about side effects (1=not concerned, 5=very concerned)
# Q2: Lack of trust in vaccine (1=strongly disagree (trust vaccine), 5=strongly agree (do not trust))
# We simulate these with a bias toward some hesitancy (higher values) since unvaccinated population tends to have more concerns.
hesitancy_q1 <- sample(1:5, N, replace = TRUE, prob = c(0.10, 0.20, 0.25, 0.25, 0.20))
hesitancy_q2 <- sample(1:5, N, replace = TRUE, prob = c(0.10, 0.20, 0.25, 0.25, 0.20))

# Combine into a baseline data frame
baseline <- data.frame(
  id = participant_id,
  age = age,
  gender = gender,
  race = race,
  income = income,
  education = education,
  region = region,
  hesitancy_q1 = hesitancy_q1,
  hesitancy_q2 = hesitancy_q2
)

# Peek at the first few rows of the baseline data
head(baseline, 5)

# Write to csv
# write.csv(baseline, "./data/baseline.csv") # uncomment it to save the baseline data
```

## Random Assignment to Ad Campaigns

Simulate the random assignment of participants into the three groups:

-   Reason-based Ad group
-   Emotion-based Ad group
-   Control group (no ad)

Each participant has an equal chance (1/3) of being in each group.
We'll create an assignment dataframe that links each participant ID to an assigned group.

```{r}
# Define the three groups
groups <- c("Reason Ad", "Emotion Ad", "Control")

# Randomly assign each participant to one of the groups (approximately 1/3 each)
assignment <- data.frame(
  id = participant_id,
  group = sample(groups, N, replace = TRUE, prob = c(1/3, 1/3, 1/3))
)

# Verify the distribution of participants in each group
table(assignment$group)

# Write to csv
write.csv(assignment, "./data/assignment.csv") # uncomment it to save the baseline data
```

The assignment table above shows the count in each group (should be roughly 1666-1667 per group for 5000 total).
Randomization should produce groups that are similar in demographics and baseline attitudes on average.

We can also merge the assignment with the baseline data now (though it's not strictly necessary yet) to verify that randomization didn't produce any major imbalances.
Therefore, we will check the average baseline hesitancy score in each group to ensure they are roughly equal.

```{r}
# Merge baseline and assignment to check baseline comparability by group
baseline_assign <- merge(baseline, assignment, by = "id")
# Compute a combined hesitancy score (average of Q1 and Q2 for a quick check)
baseline_assign$hesitancy_score <- (baseline_assign$hesitancy_q1 + baseline_assign$hesitancy_q2) / 2

# Check mean hesitancy score by group
baseline_assign %>% group_by() %>%
  summarize(mean_hesitancy = mean(hesitancy_score))

# Write to csv
write.csv(baseline_assign, "./data/baseline_assign.csv") # uncomment it to save the baseline data
```

We expect the mean baseline hesitancy to be similar across groups (any small differences are due to chance since assignment is random).
Now we proceed to simulate the outcomes in the endline survey.

## Endline Survey Simulation

After the ad campaign period, an endline survey is conducted.
Out of 5,000 initial participants, we assume some attrition (people who didn't complete the endline survey).
For simulation, we'll say 4,500 participants responded at endline (about a 10% dropout rate).
We will randomly select 4,500 IDs to have endline data, simulating missing follow-up data for the rest.

The endline dataset includes:

1.  id: Participant ID (for those who responded).

2.  vaccinated: Whether the participant got vaccinated by the end of the study (Yes/No or 1/0).

3.  post-intervention attitudes: Responses to the same hesitancy questions (Q1, Q2) at endline, to see if attitudes changed.

We simulate vaccination outcomes with a small treatment effect

-   In the control group, assume a certain baseline probability of getting vaccinated that depends on their baseline hesitancy (more hesitant individuals are less likely to vaccinate).

-   The reason-based ad and emotion-based ad groups will have slightly higher probabilities of vaccination (a minimal increase, e.g., a few percentage points higher than the control group for comparable individuals).

Specifically, we implement this as follows

1.  Determine each individual's base probability of vaccination using their baseline hesitancy score. For example, someone who was not hesitant at all (baseline hesitancy responses = 1) might have a high chance (e.g., 90%) of getting vaccinated by endline, whereas someone very hesitant (responses = 5) might have a low chance (e.g., 15%).
2.  Apply a small increase to this probability for those in the treatment groups. For instance, the reason-based ad might increase the probability by \~5 percentage points, and the emotion-based ad by \~3 points, reflecting a minimal effect.
3.  Then, draw a random outcome (vaccinated or not) for each person based on these probabilities.

We also simulate the endline hesitancy questions (Q1 and Q2 again)

-   People in the treatment groups might have slightly lower hesitancy on average at endline due to the intervention (e.g., they might be a bit less concerned or more trusting).

-   We model this by allowing each individual's Q1 and Q2 to potentially decrease by a small amount in the treatment groups (reflecting a positive attitude change), while the control group stays roughly the same.

-   We add random noise to reflect individual variation (some people become more open, others might even become more hesitant, regardless of group).

```{r}
# Determine which participants respond at endline (4500 out of 5000)
endline_ids <- sample(participant_id, size = 4500, replace = FALSE)
endline_ids <- sort(endline_ids)  # sort just for consistency (not required)

# Create a data frame for endline responses
endline <- data.frame(id = endline_ids)

# Merge baseline + assignment info to endline respondents for easier simulation of outcomes
# This gives each responding participant their baseline data and group assignment
endline <- endline %>% 
  left_join(baseline, by = "id") %>%      # add baseline demographics and attitudes
  left_join(assignment, by = "id")        # add group assignment

# Simulate vaccination outcome (0/1) with minimal treatment effect:
# We'll calculate a probability of vaccination for each person.
# Base probability depending on baseline hesitancy:
# (We use the average of Q1 and Q2 as a combined hesitancy measure for simplicity.)
endline$baseline_hesitancy_score <- (endline$hesitancy_q1 + endline$hesitancy_q2) / 2

# Define a mapping from baseline hesitancy to base vaccination probability for control:
# For hesitancy score 1 -> ~90% chance, 5 -> ~15% chance, linearly interpolate for 2-4.
# We can use a simple linear model: p = 1 - 0.2*(score - 1) - some offset
# Or define manually:
base_prob <- function(hes_score) {
  if (hes_score <= 1) return(0.90)
  if (hes_score <= 2) return(0.75)
  if (hes_score <= 3) return(0.60)
  if (hes_score <= 4) return(0.35)
  return(0.15)
}

# Apply base probabilities for control scenario
endline$base_vacc_prob <- sapply(endline$baseline_hesitancy_score, base_prob)

# Apply treatment effect adjustments to probability:
# Small increases for treatment groups
endline <- endline %>%
  mutate(vacc_prob = case_when(
    group == "Reason Ad"  ~ pmin(1, base_vacc_prob + 0.05),  # +5% for reason-based ad
    group == "Emotion Ad" ~ pmin(1, base_vacc_prob + 0.03),  # +3% for emotion-based ad
    group == "Control"    ~ base_vacc_prob
  ))

# Now determine vaccinated outcome by drawing from a Bernoulli distribution with probability = vacc_prob
endline$vaccinated <- rbinom(n = nrow(endline), size = 1, prob = endline$vacc_prob)

# Simulate endline hesitancy questions (Q1 and Q2) with possible slight improvements for treatment groups.
# We'll use the baseline values as a starting point and add random change.
# For control: assume no systematic change (mean change ~ 0).
# For reason-based: assume a small decrease in hesitancy (mean change ~ -0.2 on the 1-5 scale).
# For emotion-based: assume a smaller decrease (mean change ~ -0.1).
# We'll add random noise (normal with sd ~ 0.5) so most people change by at most 1 point.
endline <- endline %>%
  mutate(
    # Change in Q1
    q1_change = case_when(
      group == "Reason Ad"  ~ rnorm(n(), mean = -0.2, sd = 0.5),
      group == "Emotion Ad" ~ rnorm(n(), mean = -0.1, sd = 0.5),
      group == "Control"    ~ rnorm(n(), mean =  0.0, sd = 0.5)
    ),
    # Change in Q2
    q2_change = case_when(
      group == "Reason Ad"  ~ rnorm(n(), mean = -0.2, sd = 0.5),
      group == "Emotion Ad" ~ rnorm(n(), mean = -0.1, sd = 0.5),
      group == "Control"    ~ rnorm(n(), mean =  0.0, sd = 0.5)
    ),
    # Apply changes to baseline values to get endline responses, and keep within 1-5 bounds
    hesitancy_q1_end = pmin(pmax(round(hesitancy_q1 + q1_change), 1), 5),
    hesitancy_q2_end = pmin(pmax(round(hesitancy_q2 + q2_change), 1), 5)
  )

# Take a peek at the first few rows of the endline dataset
head(endline, 5)

# Select and arrange the final endline data columns of interest
endline <- endline %>%
  select(id, group, vaccinated, hesitancy_q1_end, hesitancy_q2_end)

# Write to csv
write.csv(endline, "./data/endline.csv") # uncomment it to save the endline data
```

In the above code:

1.  We computed `vacc_prob` for each participant, which is their probability of getting vaccinated given their baseline hesitancy and group.
    We then drew `endline$vaccinated` as 1 (yes) or 0 (no) based on that probability.

2.  We simulated `hesitancy_q1_end` and `hesitancy_q2_end` by taking baseline values and adding a random change (`q1_change`, `q2_change`).
    We used `round()` to get integer Likert values and then clamped them between 1 and 5 using `pmin/pmax` to respect the scale limits.

3.  Finally, we trimmed the endline dataset to just the relevant columns for analysis.

## Merge Datasets for Analysis

Now we merge the baseline, assignment, and endline information into one dataset for the analysis.
Specifically, we'll create a combined dataframe for the 4,500 participants who have endline data, including:

1.  `Demographics`,

2.  `Group assignment`,

3.  `Baseline hesitancy responses`,

4.  `Endline hesitancy responses`,

5.  `Vaccination outcome`.

This will facilitate comparisons between baseline and endline and across groups.

```{r}
# Merge baseline and assignment with endline (which already has group) to get baseline info for responders
analysis_data <- endline %>%
  left_join(baseline, by = "id")  # brings in age, gender, baseline hesitancy, etc.

# For clarity, let's rename the baseline and endline attitude columns differently
analysis_data <- analysis_data %>%
  rename(hesitancy_q1_baseline = hesitancy_q1,
         hesitancy_q2_baseline = hesitancy_q2,
         hesitancy_q1_endline  = hesitancy_q1_end,
         hesitancy_q2_endline  = hesitancy_q2_end)

# Check the size of the merged data and a snippet
dim(analysis_data)    # should be 4500 x (columns)
head(analysis_data, 3)

# Write to csv
write.csv(analysis_data, "./data/analysis_data.csv") # uncomment it to save merged data
```

## Analysis of Vaccine Uptake

First, let's compare the **vaccine uptake rates** (the percentage of participants who got vaccinated by endline) in each of the three groups.
We will calculate the vaccination rate for each group and visualize it.

```{r}
# Calculate number and percentage of vaccinated participants by group
uptake_summary <- analysis_data %>%
  group_by(group) %>%
  summarize(
    n_participants = n(),
    n_vaccinated = sum(vaccinated),
    percent_vaccinated = mean(vaccinated) * 100  # mean of 0/1 gives proportion, *100 for percentage
  )

# Display the summary table of vaccine uptake by group
kable(uptake_summary, digits = 1, col.names = c("Group", "N (responded)", "Vaccinated (N)", "Vaccinated (%)"))
```

The table above shows the number of participants in each group (who completed the endline) and how many of them got vaccinated.
The percentage vaccinated (`Vaccinated (%)`) is the primary outcome of interest.
We can see if the treatment groups have higher uptake than the control group.
Given we simulated minimal effects, the differences might be small.
Let's also visualize these percentages with a bar chart for clarity:

```{r, echo=FALSE, fig.asp=0.5, fig.align = 'center'}
# Bar plot of vaccination rate by group
ggplot(uptake_summary, aes(x = group, y = percent_vaccinated, fill = group)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = sprintf("%.1f%%", percent_vaccinated)), vjust = -0.5) +
  labs(title = "COVID-19 Vaccine Uptake by Experimental Group",
       y = "Vaccinated (%)",
       x = "Experimental Group") +
  theme_minimal() +
  theme(legend.position = "none")
```

*Figure: Percentage of participants vaccinated in each group.* The bars show the vaccination rate in each experimental condition.
We observe a slight increase in the vaccination rate for the two ad campaign groups compared to the control group.

Next, we statistically evaluate whether these differences are meaningful.
We can perform a chi-squared test of independence on a contingency table of vaccination outcome by group:

```{r}
# Contingency table of vaccination (Yes/No) by group
vacc_table <- table(analysis_data$group, analysis_data$vaccinated)
vacc_table  # show the table of counts

# Chi-square test for difference in proportions
chi_test <- chisq.test(vacc_table)
chi_test$p.value
```

The chi-square test p-value (shown above) indicates whether there's a statistically significant association between group assignment and vaccination outcome.
With 4,500 participants, even small differences might achieve significance.
In our simulation, we expect a small p-value for the overall test if at least one treatment group differs enough from control.

To pinpoint which group differences exist, one could examine the proportions

-   If, for example, the reason-based ad group has about 3-5 percentage points higher uptake than control, that might be statistically significant.

-   The emotion-based ad group might have a smaller increase (e.g., \~2-3 points) which could be not significant if very small.

For completeness, we could also fit a simple logistic regression model predicting vaccination by group (with control as baseline) to estimate effect sizes:

```{r}
# Logistic regression of vaccinated outcome on group
logit_model <- glm(vaccinated ~ group, data = analysis_data, family = binomial)
summary(logit_model)
```

In the regression output

1.  The intercept corresponds to the control group log-odds of vaccination.
2.  The coefficients for "Emotion Ad" and "Reason Ad" are the log-odds differences compared to control. We expect small positive coefficients, reflecting higher odds of vaccination in the ad groups. Converting to percentages, these might correspond to a few percentage point increases, matching our simulation design.

## Analysis of Vaccine Attitudes

Now we examine whether the ad campaigns influenced participants' **attitudes toward the vaccine**.
We compare the baseline and endline responses to the hesitancy questions for each group.

For simplicity, we'll focus on a combined **hesitancy score** which could be the average of the two questions (Q1 and Q2) or we can analyze each question similarly.
Here, let's compute an overall hesitancy score (averaging Q1 and Q2, where 5 indicates high hesitancy).
We then evaluate how this score changed from baseline to endline in each group.

```{r}
# Compute overall hesitancy score at baseline and endline (average of Q1 and Q2)
analysis_data <- analysis_data %>%
  mutate(hesitancy_score_baseline = (hesitancy_q1_baseline + hesitancy_q2_baseline) / 2,
         hesitancy_score_endline  = (hesitancy_q1_endline + hesitancy_q2_endline) / 2,
         attitude_change = hesitancy_score_endline - hesitancy_score_baseline  # change (positive means became more hesitant)
         )

# Calculate mean baseline and endline hesitancy scores by group
attitude_summary <- analysis_data %>%
  group_by(group) %>%
  summarize(
    mean_hesitancy_baseline = mean(hesitancy_score_baseline),
    mean_hesitancy_endline  = mean(hesitancy_score_endline),
    mean_change = mean(attitude_change)
  )

# Display the attitude summary table
kable(attitude_summary, digits = 2, col.names = c("Group", "Baseline Hesitancy (mean)", "Endline Hesitancy (mean)", "Mean Change"))
```

In the table above:

-   `Baseline Hesitancy (mean)`: The average hesitancy score at baseline for each group (these should be similar across groups due to randomization).

-   `Endline Hesitancy (mean)`: The average after the intervention.

-   `Mean Change`: The average change (endline minus baseline).
    A negative change would indicate a reduction in hesitancy (which is good, meaning attitudes became more pro-vaccine), while a positive change would mean attitudes became more hesitant.

We expect to see a slight decrease in hesitancy in the treatment groups relative to the control.
For example, if the control group's mean change is around 0 (or very small), the reason-based ad group might show a small negative change (indicating reduced hesitancy), perhaps around -0.1 to -0.2 on the 5-point scale on average.
The emotion-based group might show a change in between (e.g., around -0.1).
These are small shifts, consistent with a minimal effect.

Visualization

```{r, echo=FALSE, fig.asp=0.5, fig.align = 'center'}
# Prepare data for plotting baseline vs endline means by group
attitude_plot_data <- attitude_summary %>%
  select(Group = group, Baseline = mean_hesitancy_baseline, Endline = mean_hesitancy_endline) %>%
  pivot_longer(cols = c("Baseline", "Endline"), names_to = "Time", values_to = "MeanHesitancy")

# Bar plot of mean hesitancy at baseline vs endline for each group
ggplot(attitude_plot_data, aes(x = Group, y = MeanHesitancy, fill = Time)) +
  geom_col(position = "dodge", width = 0.6) +
  geom_text(aes(label = sprintf("%.2f", MeanHesitancy)), 
            position = position_dodge(width = 0.6), vjust = -0.5, size = 3) +
  labs(title = "Vaccine Hesitancy Score by Group: Baseline vs Endline",
       x = "Group", y = "Average Hesitancy (1=low, 5=high)",
       fill = "Survey") +
  theme_minimal()

```

*Figure: Average vaccine hesitancy score at baseline and endline for each group.* We see that all groups have similar starting attitudes (as expected from randomization).
After the intervention, the control group's average hesitancy remains about the same (or slightly lower due to general trends), whereas the groups that saw ads show a small decrease in hesitancy (lower scores).
The reason-based ad group appears to have the largest drop in hesitancy on average, though the difference is small.

To check the statistically significance using these anova and t-tests.

```{r}
# ANOVA to test if mean attitude change differs by group
anova_result <- aov(attitude_change ~ group, data = analysis_data)
summary(anova_result)
```

The ANOVA F-test will tell us if there's a significant difference somewhere among the three groups in terms of attitude change.
Given our simulation, we anticipate a statistically significant but small difference.
We can follow up with pairwise comparisons if needed (e.g., t-tests between each treatment and control) to pinpoint where the differences lie:

```{r}
# Pairwise t-tests for attitude change between groups (no adjustment for multiple comparisons here for simplicity)
pairwise.t.test(analysis_data$attitude_change, analysis_data$group, paired = FALSE, p.adjust.method = "none")
```

From the pairwise tests, we expect to see

1.  A significant difference between Reason Ad vs Control (the reason-based ad group has a larger reduction in hesitancy than control, p \< 0.05 if our simulation effect was around -0.2).

2.  A marginal or significant difference between Emotion Ad vs Control (if effect \~ -0.1, with large N it might still be p \< 0.05).

3.  Likely a smaller or non-significant difference between Reason Ad vs Emotion Ad (since both are treatment, their difference might be very small).

## Findings

We found that exposure to Facebook ad campaigns promoting COVID-19 vaccination led to very modest improvements in outcomes

-   The reason-based ad group had a slightly higher vaccination rate than the control group, on the order of a few percentage points.
    This difference was small but detectable given the large sample size (around 1.5k per group).
    The emotion-based ad group's uptake was also slightly higher than control but the gap was even smaller.

-   Participants who saw the ads also exhibited a minor positive shift in their attitudes.
    On average, they reported being slightly less hesitant about the vaccine at endline compared to baseline, whereas the control group's attitudes remained essentially unchanged.
    The reason-based ads again showed a slightly larger impact on improving attitudes than the emotion-based ads.

-   All these effects are minimal in magnitude. In practical terms, such small differences might or might not justify the campaign effort, but statistically, we were able to observe them in the simulation.
